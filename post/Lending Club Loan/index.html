<html>
<head>
    <meta charset="utf-8"/>
<meta name="description" content=""/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>

<title>Lending Club贷款分析及违约预测 | Dasein</title>

<link rel="shortcut icon" href="https://stdasein.life/favicon.ico?v=1600910508276">

<link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://stdasein.life/styles/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.0/dist/css/bootstrap.min.css">

<script src="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.15.10/languages/dockerfile.min.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.15.10/languages/dart.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/moment@2.27.0/moment.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.0/dist/js/bootstrap.min.js"></script>
<!-- DEMO JS -->
<!--<script src="media/scripts/index.js"></script>-->



    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.css">
</head>
<body>
<div class="main gt-bg-theme-color-first">
    <nav class="navbar navbar-expand-lg">
    <div class="navbar-brand">
        <img class="user-avatar" src="/images/avatar.png" alt="头像">
        <div class="site-name gt-c-content-color-first">
            Dasein
        </div>
    </div>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <i class="fas fa-bars gt-c-content-color-first" style="font-size: 18px"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <div class="navbar-nav mr-auto" style="text-align: center">
            
                <div class="nav-item">
                    
                        <a href="/" class="menu gt-a-link">
                            首页
                        </a>
                    
                </div>
            
                <div class="nav-item">
                    
                        <a href="/archives" class="menu gt-a-link">
                            归档
                        </a>
                    
                </div>
            
                <div class="nav-item">
                    
                        <a href="/tags" class="menu gt-a-link">
                            标签
                        </a>
                    
                </div>
            
                <div class="nav-item">
                    
                        <a href="/post/about" class="menu gt-a-link">
                            关于
                        </a>
                    
                </div>
            
        </div>
        <div style="text-align: center">
            <form id="gridea-search-form" style="position: relative" data-update="1600910508276" action="/search/index.html">
                <input class="search-input" autocomplete="off" spellcheck="false" name="q" placeholder="搜索文章" />
                <i class="fas fa-search gt-c-content-color-first" style="position: absolute; top: 9px; left: 10px;"></i>
            </form>
        </div>
    </div>
</nav>

    <div class="post-container">
        <div class="post-detail gt-bg-theme-color-second">
            <article class="gt-post-content">
                <h2 class="post-title">
                    Lending Club贷款分析及违约预测
                </h2>
                <div class="post-info">
                    <time class="post-time gt-c-content-color-first">
                        · 2020-09-15 ·
                    </time>
                    
                        <a href="https://stdasein.life/tag/9S8F6aIMy/" class="post-tags">
                            # 数据分析
                        </a>
                    
                </div>
                <div class="post-content">
                    <h3 id="一-项目背景">一、项目背景</h3>
<p><strong>背景介绍</strong></p>
<blockquote>
<p>作为旧金山的一家个人对个人的借贷公司，Lending Club利用网络技术打造交易平台，直接连接了个人投资者和个人借贷者，通过此种方式，缩短了资金流通的细节，尤其是绕过了传统的大银行等金融机构，使得投资者和借贷者都能得到更多实惠、更快捷。对于投资者来说可以获得更好的回报，而对于借贷者来说，则可以获得相对较低的贷款利率。</p>
</blockquote>
<p><strong>数据来源</strong></p>
<p><a href="https://www.kaggle.com/wordsforthewise/lending-club/discussion">Kaggle:All Lending Club loan data</a></p>
<h3 id="二-提出问题">二、提出问题</h3>
<ul>
<li>通过探索性数据分析建立用户画像</li>
<li>利用机器学习进行违约预测</li>
</ul>
<h3 id="三-分析框架">三、分析框架</h3>
<figure data-type="image" tabindex="1"><img src="https://stdasein.life/post-images/1600135592031.png" alt="" width="500" height="300" loading="lazy"></figure>
<h3 id="四-前期准备">四、前期准备</h3>
<p>设置基本环境，导入pandas、numpy等要用到的库</p>
<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# 忽略弹出的warnings
import warnings
warnings.filterwarnings('ignore') 
# 指定默认字体
plt.rcParams['font.sans-serif'] = ['SimHei']  
# 解决保存图像是负号'-'显示为方块的问题
plt.rcParams['axes.unicode_minus'] = False 
</code></pre>
<p>探索文件体积大小，以防后续出现加载过慢或内存报错等问题</p>
<pre><code class="language-python">count = 0
fp = open('lendingclub.csv', &quot;r&quot;, encoding='utf-8')
while 1:
    buffer = fp.read(8*1024*1024)
    if not buffer:
        break
    count += buffer.count('\n')
print(count)
print('over')
fp.close()
</code></pre>
<pre><code class="language-python">2260702
over
</code></pre>
<p>文件有200多万行，这可能导致内存不足，因此我们选择通过chunksize参数选取部分内容进行分析，chunksize的具体用法参见<a href="https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas/12193309#12193309"><strong>Stack Overflow</strong></a></p>
<pre><code class="language-python">path = 'lendingclub.csv'
reader = pd.read_csv(path,chunksize = 500000)

for i,ck in enumerate(reader):
    print(i,'',len(ck))
    ck.to_csv('D:\学习\jupyter notebook'+str(i)+'.csv', index=False)
</code></pre>
<pre><code class="language-python">0  500000
1  500000
2  500000
3  500000
4  260701
</code></pre>
<p>我们将文件分成了5块，选择其中行数为260,701的1块进行分析</p>
<pre><code class="language-python">path = 'D:\学习\jupyter notebook4.csv'
data = pd.read_csv(path)
</code></pre>
<h3 id="五-探索性数据分析eda">五、探索性数据分析（EDA)</h3>
<p>探索性数据分析（EDA)是指<strong>通过作图、制表、计算特征量等手段探索数据的结构和规律的一种数据分析方法</strong>，旨在为后续的流程提供决策辅助，其分析框架如下图所示:</p>
<figure data-type="image" tabindex="2"><img src="https://stdasein.life/post-images/1600135732992.png" alt="" width="500" height="300" loading="lazy"></figure>
<h4 id="1概况分析">1.概况分析</h4>
<p>在这个环节我们的关注点集中在数据集的整体概况上，要求从特征值数量、数据质量、数据类型等方面对数据集进行评估。</p>
<p>查看数据集的样本数量和每个样本的特征数量：</p>
<pre><code class="language-python">data.shape
</code></pre>
<pre><code class="language-python">(260701, 151)
</code></pre>
<p>可见，数据集有260,701名用户的贷款资料，且有151个分析维度（贷款金额、工作年限等）</p>
<p>查看前5个样本：</p>
<pre><code class="language-python">data.head()
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://stdasein.life/post-images/1600135976132.png" alt="" loading="lazy"></figure>
<p>注意：这里只截取了部分特征。显然，有些特征（例如member_id）有较多的缺失值，可考虑在数据预处理环节进行进一步分析、清理。</p>
<p>进行描述性统计分析：</p>
<pre><code>data.describe(include = 'all')
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://stdasein.life/post-images/1600136090223.png" alt="" loading="lazy"></figure>
<p>describe()函数可以帮助我们了解数据的集中趋势（均值、众数）、离散程度（极差、标准差）和分布状况（分位数）等，而对于类别型数据，则能够提供唯一值数量、频数最高的值等信息。以emp_title为例，我们可以得知在众多贷款者中，从事最多的职业是老师，这揭示了金融机构放贷的偏好。</p>
<p>查看数据类型：</p>
<pre><code class="language-python">num_feature = data.select_dtypes(include = ['number']).columns
num_feature
</code></pre>
<pre><code class="language-python">Index(['member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'int_rate',
       'installment', 'annual_inc', 'dti', 'delinq_2yrs', 'fico_range_low',
       ...
       'deferral_term', 'hardship_amount', 'hardship_length', 'hardship_dpd',
       'orig_projected_additional_accrued_interest',
       'hardship_payoff_balance_amount', 'hardship_last_payment_amount',
       'settlement_amount', 'settlement_percentage', 'settlement_term'],
      dtype='object', length=113)
</code></pre>
<pre><code class="language-python">cat_feature = data.select_dtypes(include = ['object']).columns
cat_feature
</code></pre>
<pre><code class="language-python">Index(['id', 'term', 'grade', 'sub_grade', 'emp_title', 'emp_length',
       'home_ownership', 'verification_status', 'issue_d', 'loan_status',
       'pymnt_plan', 'url', 'desc', 'purpose', 'title', 'zip_code',
       'addr_state', 'earliest_cr_line', 'initial_list_status', 'last_pymnt_d',
       'next_pymnt_d', 'last_credit_pull_d', 'application_type',
       'verification_status_joint', 'sec_app_earliest_cr_line',
       'hardship_flag', 'hardship_type', 'hardship_reason', 'hardship_status',
       'hardship_start_date', 'hardship_end_date', 'payment_plan_start_date',
       'hardship_loan_status', 'disbursement_method', 'debt_settlement_flag',
       'debt_settlement_flag_date', 'settlement_status', 'settlement_date'],
      dtype='object')
</code></pre>
<p>经过初步筛选，我们发现数据集中有113个数值型特征，其余皆为分类型，然而有些特征的类型需要在后续进行调整，例如工作年限em_length可能归为数值型更合适。</p>
<h4 id="2用户画像">2.用户画像</h4>
<p><strong>（1）用户基本信息</strong></p>
<figure data-type="image" tabindex="5"><img src="https://stdasein.life/post-images/1600136180233.png" alt="" width="500" height="300" loading="lazy"></figure>
<p><strong>地域分布（颜色越深表示该区域客户数量越多）</strong></p>
<figure data-type="image" tabindex="6"><img src="https://stdasein.life/post-images/1600136333092.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>分析发现：客户数量最多的前四个州分别是加州(35,048）、德州(22,007)、纽约(21,210)和弗罗里达(19,519)，而爱荷华客户数量最少(0)；此外，沿海地区的客户数量整体上要高于内陆地区。</p>
<p>提出假设：贷款数量与区域经济发展程度有关。</p>
<p>验证假设：我们可以将平均年收入和总年收入作为衡量一个州经济发展程度的指标，以此来验证先前提出的假设。</p>
<figure data-type="image" tabindex="7"><img src="https://stdasein.life/post-images/1600136406450.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>上图中，方块越大代表总收入越高，而颜色越红代表年均收入越高。</p>
<p>我们可以看见，经济规模前四的州分别是加州、德州、纽约和弗罗里达，正好与贷款数量前四的州一一对应；同时，年均收入较高的州（颜色红）大部分都位于沿海地区。</p>
<p><strong>收入分布</strong></p>
<figure data-type="image" tabindex="8"><img src="https://stdasein.life/post-images/1600136477730.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>分析发现：客户收入呈现正偏态分布（即平均数大于中位数，中位数大于众数），其中，位于4,0000-6,0000美元收入区间内的客户人数最多。</p>
<p>提出假设：相较于高收入人群，收入中等偏下的人群有更高的贷款需求，而低收入人群则更难通过贷款审核。</p>
<p><strong>职业分布</strong></p>
<figure data-type="image" tabindex="9"><img src="https://stdasein.life/post-images/1600136564750.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>分析发现：除了经理(manager)这一职业占比高达14.98%外，前十名的其他职业，例如主管(Supervisor 2.87%)、老师(2.86%)等，占比差距并不大。</p>
<p>提出假设：以经理为职业的人群收入更高，机构更容易发放贷款。</p>
<p>验证假设：我们可以尝试加入<strong>年收入中值</strong>维度进行分析（以颜色表示，从深绿到深黄，年收入中值递增）</p>
<figure data-type="image" tabindex="10"><img src="https://stdasein.life/post-images/1600136641266.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>结果显示，尽管经理的收入在前十的职业中并不低，但也没有明显的优势，不能简单的认为其数量优势是来自与高收入，因此假设不成立。</p>
<p>修改假设：经理可能是更具代表性的管理层的一种泛称，客户倾向于使用这样的称呼来代替具体的管理职务。</p>
<p><strong>工作年限</strong></p>
<p>根据经验，工作年限越长收入越高，因此我们可以将工作年限与收入进行组合分析来验证这一点。</p>
<figure data-type="image" tabindex="11"><img src="https://stdasein.life/post-images/1600136744140.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>分析发现：收入与工作年限成正比（由绿到红）；10年及以上工作年限的客户占比最高（36.08%），说明贷款机构偏好高工作年限的客户，但另一方面，低工作年限（0-3年）的人群占比也接近35%。</p>
<p>提出假设：<strong>贷款机构可能通过提高利率、降低贷款额来弥补风险（对低工作年限人群）</strong></p>
<p>验证假设</p>
<figure data-type="image" tabindex="12"><img src="https://stdasein.life/post-images/1600136823891.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>总的来说，工作年限越高，贷款额度越高，同时，利率也越低（红到灰），假设成立。</p>
<p><strong>住房情况</strong></p>
<figure data-type="image" tabindex="13"><img src="https://stdasein.life/post-images/1600136893018.png" alt="" width="400" height="300" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://stdasein.life/post-images/1600137021854.png" alt="" width="200" height="100" loading="lazy"></figure>
<p>分析发现：约半数的客户有抵押贷款，经济实力较强、拥有自己的房子的客户仅占12.35%，而剩下的将近40%的客户处于租房住的状态。</p>
<p>提出假设：住房情况与工作年限、收入正相关。</p>
<p>验证假设：通过仪表板关联图表进行分析</p>
<figure data-type="image" tabindex="15"><img src="https://stdasein.life/post-images/1600137100977.png" alt="" width="600" height="300" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://stdasein.life/post-images/1600137167889.png" alt="" width="600" height="300" loading="lazy"></figure>
<p>对比发现，40%拥有住房的客户工作年限在10年以上，而租房客户仅占约26%，假设成立。</p>
<p><strong>贷款目的</strong></p>
<figure data-type="image" tabindex="17"><img src="https://stdasein.life/post-images/1600137237767.png" alt="" width="600" height="300" loading="lazy"></figure>
<p>分析发现：大部分贷款目的（55%债务重组、20%还信用卡，总共75%）是借新债还旧债。</p>
<p>提出假设：以还债为目的的贷款利率更高。</p>
<p>验证假设：以利率和贷款目的为坐标轴画散点图<br>
<img src="https://stdasein.life/post-images/1600137328383.png" alt="" width="600" height="300" loading="lazy"><br>
信用卡、债务重组项的利率并不突出，假设不成立。</p>
<p><strong>月偿还额收入比</strong></p>
<figure data-type="image" tabindex="18"><img src="https://stdasein.life/post-images/1600137404488.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>大部分客户的月偿还收入比都在30%以下，其中偿收比在10%-21%的人群占比约为55%，可见，整体上，客户群体的偿债能力还是比较高的。</p>
<p><strong>（2）客户信用记录</strong></p>
<ul>
<li>借款者过去两年借款逾期超过30天次数</li>
<li>距离最近逾期的月份数</li>
<li>负面记录</li>
<li>违约金额</li>
</ul>
<p><strong>借款者过去两年借款逾期超过30天次数</strong></p>
<figure data-type="image" tabindex="19"><img src="https://stdasein.life/post-images/1600137472539.png" alt="" width="400" height="300" loading="lazy"></figure>
<p>气泡图显示，81.05%的客户在近两年不存在逾期行为，说明大部分客户还是信用良好的，而在有逾期行为的客户中，逾期1次的占多数（12.6%）。</p>
<p><strong>距离最近一次逾期的月数&amp;负面记录分析</strong></p>
<figure data-type="image" tabindex="20"><img src="https://stdasein.life/post-images/1600137546639.png" alt="" width="400" height="300" loading="lazy"></figure>
<figure data-type="image" tabindex="21"><img src="https://stdasein.life/post-images/1600137610640.png" alt="" width="400" height="300" loading="lazy"></figure>
<p>分析发现：如果把时间维度拉长，曾有逾期行为的客户数量将增至接近总数的一半（130,026），但是，机构对客户的负面记录基本与近两年逾期情况的分布一致，这可能说明在很大程度上，机构只考虑前两年的信用状况。</p>
<p><strong>违约金额分布</strong></p>
<figure data-type="image" tabindex="22"><img src="https://stdasein.life/post-images/1600137685878.png" alt="" width="550" height="300" loading="lazy"></figure>
<figure data-type="image" tabindex="23"><img src="https://stdasein.life/post-images/1600137758612.png" alt="" width="100" height="200" loading="lazy"></figure>
<p>分析发现：从整体上来说，逾期次数与逾期金额成反比，逾期金额主要分布在1100美元以下的区间内，其中0—200美元区间内的逾期次数最多。逾期的贷款多是用于借新债还旧债，与贷款目的分布一致。</p>
<p><strong>（3）产品数据</strong></p>
<ul>
<li>借款者的信用等级</li>
<li>贷款额度</li>
<li>贷款期限</li>
<li>贷款利率</li>
<li>贷款状态</li>
</ul>
<p><strong>信用等级、贷款额度与利率（不同的形状代表不同的信用等级，颜色代表频率）</strong></p>
<figure data-type="image" tabindex="24"><img src="https://stdasein.life/post-images/1600137829120.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>分析发现：</p>
<ul>
<li>利率与信用等级成反比，信用等级越低则利率越高，其中A级信用的利率均值仅为7.03%，而G级却高达30.35%;</li>
<li>B级和C级发放贷款的总量最高，G级最低。</li>
</ul>
<p><strong>贷款额度、利率与期限（颜色代表贷款额度）</strong></p>
<figure data-type="image" tabindex="25"><img src="https://stdasein.life/post-images/1600137893038.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>分析发现：机构偏向发放低期限的贷款，尽管高期限的贷款利率更高，可能是出于规避风险的需要。</p>
<p><strong>贷款状态</strong></p>
<figure data-type="image" tabindex="26"><img src="https://stdasein.life/post-images/1600137971630.png" alt="" width="400" height="250" loading="lazy"></figure>
<p>分析发现:</p>
<ul>
<li>有53.19%的贷款还在进行中，无法判断最终是否形成坏账</li>
<li>有33.82%的贷款顺利完成；</li>
<li>有10.48%的借款无法收回（charged off）</li>
<li>有1.62%的客户存在逾期（30-120天）</li>
</ul>
<h3 id="六-数据预处理">六、数据预处理</h3>
<figure data-type="image" tabindex="27"><img src="https://stdasein.life/post-images/1600138044677.png" alt="" width="500" height="300" loading="lazy"></figure>
<h4 id="1处理缺失值">1.处理缺失值</h4>
<figure data-type="image" tabindex="28"><img src="https://stdasein.life/post-images/1600138099943.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>处理缺失值主要有5种方法：</p>
<ul>
<li>删除含有缺失值的特征：适用于缺失值过多的特征</li>
<li>特殊值填充：这个是认为数据的空值也是具有一定的信息的，它之所以为空，是因为它不同于其他的任何数据。所以将空值作为一种特殊的属性值来处理，它不同于其他的任何属性值。如所有的空值都用“unknown”填充。</li>
<li>统计值填充：如果空值是<strong>数值型</strong>的，就根据该属性在其他所有对象的取值的统计值（例如平均值）来填充该缺失的属性值；如果空值是<strong>非数值型</strong>的，就根据统计学中的众数原理，用该属性在其他所有对象的取值次数最多的值(即出现频率最高的值)来补齐该缺失的属性值。</li>
<li>最近邻法：先根据欧式距离或相关分析来确定距离具有缺失数据样本最近的K个样本，将这K个值加权平均来估计该样本的缺失数据。缺点：在于难以定义相似标准，主观因素较多。</li>
<li>模型预测：基于完整的数据集，建立预测模型。对于包含空值的对象，将已知属性值代入方程来估计未知属性值，以此估计值来进行填充。其实就是假设特征之间也存在一定的关系，可以通过预测来得到缺失值。但是我个人不建议使用这个方法，因为有些麻烦，而且不确定这样得到的填充值的效果。又<strong>可能出现模型过拟合等新问题</strong>。</li>
</ul>
<p>为了方便起见，我们选择前三种方法处理缺失值。</p>
<p><strong>（1）查看缺失值分布</strong></p>
<pre><code class="language-python">#定义计算各特征缺失比例的函数
def CountNull(data):
    null_count = data.isnull().sum().sort_values(ascending = False)
    ratio = null_count/len(data)
    nulldata = pd.concat([null_count,ratio],axis = 1, keys=['count','ratio'])
    return nulldata[ratio&gt;0]

CountNull(data)
</code></pre>
<figure data-type="image" tabindex="29"><img src="https://stdasein.life/post-images/1600138239863.png" alt="" width="400" height="300" loading="lazy"></figure>
<p><strong>（2）使用dropna删除含缺失值的特征</strong></p>
<p>通过查看缺失值的分布，我们发现部分特征的缺失情况很严重，有的缺失比例甚至能够达到99%以上，这样的特征对预测没有实际的意义，可以考虑设置阈值（例如缺失比达到50%），并用dropna删除达到阈值的特征。</p>
<pre><code class="language-python">#用dropna删去缺失值比例大于50%的特征
half_count = len(data)/2 
data = data.dropna(thresh = half_count, axis = 1 ) 
</code></pre>
<pre><code class="language-python">data.shape
</code></pre>
<pre><code class="language-python">(260701, 108)
</code></pre>
<pre><code class="language-python">CountNull(data)
</code></pre>
<figure data-type="image" tabindex="30"><img src="https://stdasein.life/post-images/1600138406848.png" alt="" width="400" height="300" loading="lazy"></figure>
<p>经过筛选，特征重由原来的151个变为108个。</p>
<p><strong>（3）填充缺失值</strong></p>
<p><strong>填充数值型特征的缺失值</strong></p>
<ul>
<li>
<p>筛选空值有含义的特征，填充特殊值</p>
</li>
<li>
<p>对于其余特征，包括缺失值占比在1%以下的特征，直接用平均值进行填充。</p>
</li>
</ul>
<pre><code class="language-python">#筛选数值型特征
num_feature = data.select_dtypes('number')
num_names = num_feature.columns
num_names
</code></pre>
<pre><code class="language-python">Index(['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'int_rate',
       'installment', 'annual_inc', 'loan_status', 'dti', 'delinq_2yrs',
       'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'open_acc',
       'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp',
       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',
       'total_rec_int', 'total_rec_late_fee', 'recoveries',......])
</code></pre>
<p>根据官方的说明文件，'il_util','num_tl_120dpd_2m','bc_util'的空值等同于0，以此我们可以将其筛选出来。另外，'mths_since_recent_inq'表示距离最近一次逾期的月份数，缺失值可能是因为客户不存在逾期情况，我们可以选择填充一个较大的数字，例如100，将其与其他情况区分开来。</p>
<pre><code class="language-python">num_zero = ['il_util','num_tl_120dpd_2m','bc_util']
num_100  = ['mths_since_recent_inq']
data[num_zero] = data[num_zero].fillna(0)
data[num_100] = data[num_100].fillna(100)
</code></pre>
<p>对余下的特征用均值进行填充</p>
<pre><code class="language-python">#筛选含有缺失值的数值型特征
num_null = CountNull(data).index
nominal_null_feature = [i for i in num_null if i in num_names]
#填充均值
data[nominal_null_feature] = data[nominal_null_feature].fillna(data[nominal_null_feature].mean())
</code></pre>
<p><strong>填充类别型特征的缺失值</strong></p>
<ul>
<li>直接填充'Unknown'</li>
</ul>
<pre><code class="language-python">cat_feature =  data.select_dtypes('object')
cat_names = cat_feature.columns
cat_names
</code></pre>
<pre><code class="language-python">Index(['id', 'term', 'grade', 'sub_grade', 'emp_title', 'emp_length',
       'home_ownership', 'verification_status', 'issue_d', 'pymnt_plan', 'url',
       'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line',
       'initial_list_status', 'last_pymnt_d', 'next_pymnt_d',
       'last_credit_pull_d', 'application_type', 'hardship_flag',
       'disbursement_method', 'debt_settlement_flag'],
      dtype='object')
</code></pre>
<pre><code class="language-python">data[cat_names] = data[cat_names].fillna('Unknown')
data.isnull().sum()
</code></pre>
<h4 id="2处理异常值">2.处理异常值</h4>
<figure data-type="image" tabindex="31"><img src="https://stdasein.life/post-images/1600138468584.png" alt="" width="500" height="300" loading="lazy"></figure>
<p><strong>（1）简单统计</strong></p>
<pre><code class="language-python">des = data.describe()
des.sort_values(by = 'std',ascending = False,axis = 1)
</code></pre>
<figure data-type="image" tabindex="32"><img src="https://stdasein.life/post-images/1600138545220.png" alt="" loading="lazy"></figure>
<p>对标准差进行排序后，我们发现'tot_hi_cred_lim'（最高限额）的离散程度最大，这说明该特征可能存在异常值，需要我们作出进一步的判断。</p>
<p>我们可以利用散点图找出异常值，x变量为最高限额，y变量为年收入。</p>
<pre><code class="language-python">import seaborn as sns
sns.scatterplot(x = 'tot_hi_cred_lim', y = 'annual_inc', data = data)
</code></pre>
<p><img src="https://stdasein.life/post-images/1600138604084.png" alt="" width="500" height="300" loading="lazy"><br>
一般来说，信用额度与收入成正比，但右下角的点显然不符合这一规律，我们可以将其视为异常点进行删除</p>
<pre><code class="language-python">data[data['tot_hi_cred_lim'] &gt; 5000000]
</code></pre>
<figure data-type="image" tabindex="33"><img src="https://stdasein.life/post-images/1600138666499.png" alt="" loading="lazy"></figure>
<pre><code class="language-python">data.drop([101679,235281], axis = 0, inplace = True)
</code></pre>
<p><strong>（2）使用IsolationForest剔除异常值</strong></p>
<p>IsolationForest是适用于连续数据的无监督异常检测方法，该算法会将数据只占很少量、数据特征值和正常数据差别很大的值视为异常值。</p>
<pre><code class="language-python">data.shape
</code></pre>
<pre><code class="language-python">(260697, 108)
</code></pre>
<pre><code class="language-python">#建立算法模型：
from sklearn.ensemble import IsolationForest
iso = IsolationForest()
#剔除异常值：mask表示不含有异常值的行
yhat = iso.fit_predict(data[num_names])
mask = yhat != -1
data_iso = data.values[mask, :]
data_iso = pd.DataFrame(data_iso,columns = data.columns)
#转换数据类型
data_iso[num_names] = data_iso[num_names].astype('int')
data_iso.shape
</code></pre>
<pre><code class="language-python">(254811, 108)
</code></pre>
<p>可见，算法剔除了5,886个样本。让我们来看看剔除部分异常值后的效果：</p>
<pre><code class="language-python">data_iso.describe().sort_values(by = 'std',axis = 1,ascending = False)
</code></pre>
<figure data-type="image" tabindex="34"><img src="https://stdasein.life/post-images/1600138737916.png" alt="" loading="lazy"></figure>
<p>剔除了部分异常值后，数据的离散程度有所下降，但相对而言还是比较高，这可能是由贫富差距导致的，反映了现实的状况。</p>
<h4 id="3过滤冗余特征">3.过滤冗余特征</h4>
<p>冗余特征可以分为三类：</p>
<ul>
<li>与预测无关的特征</li>
<li>无区分度的特征</li>
<li>信息重复的特征</li>
</ul>
<p>（1）与预测无关的特征</p>
<p>没有实际意义：id; zip_code地址邮编；addr_state申请地址；url:网站链接; emp_title职位名称（在数据探索阶段进行了分析）；next_pymnt_d；last_pymnt_d；issue_d；earliest_cr_line；last_credit_pull_d</p>
<p>信息泄露：collection_recovery_fee; recoveries</p>
<p>（2）无区分度的特征</p>
<pre><code class="language-python">data_iso.nunique()
nuniq[nuniq == 1]
</code></pre>
<pre><code class="language-python">policy_code    1
</code></pre>
<p>policy_code的值全为1，对预测没有影响，可以删去</p>
<p>（3）信息重复的特征</p>
<p>title： title与purpose的信息重复</p>
<p>sub_grade：与Grade的信息重复</p>
<p>通过drop将上述筛选出来的冗余特征删除：</p>
<pre><code class="language-python">drop_features = ['emp_title','id','policy_code','zip_code','addr_state','url',
                 'next_pymnt_d','last_pymnt_d','collection_recovery_fee',
                 'last_pymnt_amnt','issue_d','title','sub_grade','last_credit_pull_d',
                 'earliest_cr_line']
data_iso.drop(drop_features,axis=1,inplace = True)
</code></pre>
<h3 id="七-特征工程">七、特征工程</h3>
<blockquote>
<p>什么是特征工程呢？一个非常简单的例子，现在出一非常简答的二分类问题题，请你使用逻辑回归，设计一个身材分类器。输入数据X:身高和体重 ，标签为Y:身材等级（胖，不胖）。显然，不能单纯的根据体重来判断一个人胖不胖，姚明很重，他胖吗？显然不是。针对这个问题，一个非常经典的特征工程是，**BMI指数，BMI=体重/(身高^2)。这样，通过BMI指数，**就能非常显然地帮助我们，刻画一个人身材如何。<strong>甚至，你可以抛弃原始的体重和身高数据。所以说，特征工程就是</strong>通过X，创造新的X'。<strong>基本的操作包括:衍生（升维），筛选（降维）</strong></p>
</blockquote>
<figure data-type="image" tabindex="35"><img src="https://stdasein.life/post-images/1600138783381.png" alt="" width="500" height="300" loading="lazy"></figure>
<h4 id="1特征衍生">1.特征衍生</h4>
<p>特征衍生就是通过现有特征来构建新特征，以提升机器学习的准确度。</p>
<p>根据原有特征，我们可以尝试构建以下新特征：</p>
<ul>
<li>
<p>fico信用评分均值：数据集给出了fico信用评分的上下限，我们可以以此构建fico评分的均值并删除原来的特征。</p>
</li>
<li>
<p>构建信用额度使用率：通过不同账户的信用余额/信用额度，可以获得每个账户的信用额度使用率，该特征可以衡量客户的资金使用情况。</p>
</li>
<li>
<p>构建总借款账户数量：将不同借款账户数量简单相加。</p>
</li>
</ul>
<pre><code class="language-python">#fico评分均值
data_iso['fico_avg'] = (data_iso['fico_range_low']+data_iso['fico_range_high'])/2
#用户分期账户信用额度使用率
data_iso['installment_ratio'] =  data_iso['total_bal_il']/ data_iso['total_il_high_credit_limit']
#循环贷款信用额度使用率
data_iso['credit_revolving_ratio'] = data_iso['revol_bal']/ data_iso['total_rev_hi_lim']
#总信用额度使用率
data_iso['total_ratio'] =  data_iso['total_bal_ex_mort']/ data_iso['tot_hi_cred_lim']
#借款账户数 = 抵押贷款账户数+分期付款账户数+循环账户数
data_iso['num_accounts'] = data_iso['mort_acc'] + data_iso['num_il_tl'] + data_iso['num_rev_accts']
</code></pre>
<h4 id="2特征规整">2.特征规整</h4>
<figure data-type="image" tabindex="36"><img src="https://stdasein.life/post-images/1600138826745.png" alt="" width="500" height="300" loading="lazy"></figure>
<p><strong>（1）数值型特征规整</strong></p>
<p><strong>特征缩放</strong></p>
<blockquote>
<p>在运用一些机器学习算法的时候不可避免地要对数据进行特征缩放（feature scaling），比如：在随机梯度下降（stochastic gradient descent）算法中，特征缩放有时能提高算法的收敛速度。特征缩放还可以使机器学习算法工作的更好。比如在K近邻算法中，分类器主要是计算两点之间的欧几里得距离，如果一个特征比其它的特征有更大的范围值，那么距离将会被这个特征值所主导。</p>
</blockquote>
<p>数据整理、筛选：</p>
<pre><code class="language-python">#将'loan_status'转换为0和1的形式，不存在违约行为（Current、Fully Paid）用0表示，其余用1表示
map_loan_status = {'Current':0,'Fully Paid':0,'In Grace Period':1,'Late (31-120 days)':1,'Late (16-30 days)':1,'Charged Off':1}
data_iso['loan_status']= data_iso['loan_status'].map(map_loan_status)
data_iso['loan_status'] = data_iso['loan_status'].astype('object')
#筛选数值型特征
num_features = data_iso.select_dtypes('number')
num_names = num_features.columns
#因为构建的新特征可能重新引入无穷值和缺失值，所以要再次进行处理
data_iso.replace([np.inf, -np.inf], np.nan, inplace=True)
data_iso.fillna(0, inplace=True)
</code></pre>
<p>使用sklearn工具进行缩放：</p>
<pre><code class="language-python">#引入标准化工具并进行标准化
from sklearn.preprocessing import MinMaxScaler
#创建对象，限定范围（1，2）
scaler = MinMaxScaler(feature_range=(1, 2))
data_iso[num_names] = scaler.fit_transform(data_iso[num_names])
data_iso[num_names].head()
</code></pre>
<figure data-type="image" tabindex="37"><img src="https://stdasein.life/post-images/1600138900422.png" alt="" loading="lazy"></figure>
<p>缩放后，数值的大小被控制在1到2之间。</p>
<p><strong>（2）类别型特征规整</strong></p>
<pre><code class="language-python">cat_features = data_iso.select_dtypes('object')
cat_names = cat_features.columns
cat_names
</code></pre>
<pre><code class="language-python">Index(['term','grade','emp_length','home_ownership', 'verification_status', 'pymnt_plan',
       'purpose', 'initial_list_status', 'application_type', 'hardship_flag',
       'disbursement_method', 'debt_settlement_flag'],
      dtype='object')
</code></pre>
<p><strong>有序变量</strong></p>
<p>数据特征中存在一些顺序变量(ordinal variable),它们不同于一般的类型变量（categorical variable），顺序变量之间存在固有的顺序 比如 (低, 中, 高)。</p>
<ul>
<li><strong>grade</strong>评级 (信用风险:A&lt;B&lt;C&lt;D&lt;E&lt;F&lt;G)</li>
<li><strong>emp_length</strong>工作年限</li>
</ul>
<p>对有序变量，我们可以采用手动编码来体现顺序关系：</p>
<pre><code class="language-python">#对grade进行编码
grade_dict = {'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7,'Unknown':8}
data_iso['grade'] = data_iso['grade'].map(grade_dict)
</code></pre>
<pre><code class="language-python">#对emp_length进行编码
emp_length_dict = {&quot;10+ years&quot;: 10,
                    &quot;9 years&quot;: 9,
                    &quot;8 years&quot;: 8,
                    &quot;7 years&quot;: 7,
                    &quot;6 years&quot;: 6,
                    &quot;5 years&quot;: 5,
                    &quot;4 years&quot;: 4,
                    &quot;3 years&quot;: 3,
                    &quot;2 years&quot;: 2,
                    &quot;1 year&quot;: 1,
                    &quot;&lt; 1 year&quot;: 0,
                    &quot;Unknown&quot;: 0
                  }
data_iso['emp_length'] = data_iso['emp_length'].map(emp_length_dict)
</code></pre>
<pre><code class="language-python">data_iso[['grade','emp_length']]
</code></pre>
<figure data-type="image" tabindex="38"><img src="https://stdasein.life/post-images/1600138946607.png" alt="" loading="lazy"></figure>
<p>编码后，特征值变为有顺序的数值。</p>
<p><strong>无序变量</strong></p>
<p>对于无序变量，我们可以使用pandas自带的get_dummies来进行独热编码。所谓独热编码，指的是用0和1来表示一个特征值，例如，颜色特征里面有两个特征值（蓝和绿），进行独热编码后，蓝就表示为（1，0），而绿就是（0，1），具体使用见<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html">官方文档</a></p>
<pre><code class="language-python">#用get_dummies对剩下的类别型特征进行独热编码
data_iso = pd.get_dummies(data_iso)
data_iso.head()
</code></pre>
<figure data-type="image" tabindex="39"><img src="https://stdasein.life/post-images/1600139004670.png" alt="" loading="lazy"></figure>
<p>截取了部分特征转换后的样子，可以看见，application_type被扩展成了3个特征。</p>
<h4 id="3特征选择">3.特征选择</h4>
<blockquote>
<p>通过特征选择减少特征具有重要的现实意义，不仅减少过拟合、减少特征数量（降维）、提高模型泛化能力，而且还可以使模型获得更好的解释性，增强对特征和特征值之间的理解，加快模型的训练速度，一般的，还会获得更好的性能。</p>
</blockquote>
<figure data-type="image" tabindex="40"><img src="https://stdasein.life/post-images/1600139052155.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>特征选择的方法主要有三种：过滤法、嵌入法、包装法</p>
<ul>
<li>过滤法：完全独立于任何机器学习算法。它是根据各种<strong>统计检验中的分数以及相关性的各项指标</strong>来选择特征，适合在<strong>数据量很大</strong>的时候使用。</li>
<li>嵌入法：相比于过滤法**，嵌入法的结果会更加精确到模型的效用本身，对于提高模型效力有更好的效果**。并且，由于考虑特征对模型的贡献，因此无关的特征（需要相关性过滤的特征）和无区分度的特征（需要方差过滤的特征）都会因为缺乏对模型的贡献而被删除掉，可谓是<strong>过滤法的进化版</strong>，因此可以完全不过滤，直接使用嵌入法。</li>
<li>包装法：区别于过滤法和嵌入法的一次训练解决所有问题，包装法要<strong>使用特征子集进行多次训练</strong>，因此它所需要的<strong>计算成本是最高</strong>的。</li>
</ul>
<p>考虑到数据量比较大和算力有限，<strong>嵌入法</strong>结合<strong>过滤法</strong>是比较合适的选择。</p>
<p><strong>（1）嵌入法</strong></p>
<pre><code class="language-python">#分离特征和预测标签
X = data_iso.drop(['loan_status'],axis = 1)
y = data_iso['loan_status']
</code></pre>
<p><strong>找到阈值（阈值决定要保留多少特征，阈值越高，保留的特征越少）</strong></p>
<pre><code class="language-python">#通过学习曲线探索阈值
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier as RFC
from sklearn.model_selection import cross_val_score

RFC_ = RFC(n_estimators = 10,random_state = 42) 

threshold = np.linspace(0,(RFC_.fit(X,y).feature_importances_).max(),20)

score = []
for i in threshold:
    X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y)
    once = cross_val_score(RFC_,X_embedded,y,cv=5).mean()
    score.append(once)
plt.plot(threshold,score)
plt.show()
</code></pre>
<figure data-type="image" tabindex="41"><img src="https://stdasein.life/post-images/1600139113112.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>学习曲线显示，当阈值在0-0.02附近时，模型的评分最高，我们可以进一步细化学习曲线找到具体的值：</p>
<pre><code class="language-python">#细化学习曲线
score2 = []
for i in np.linspace(0,0.02,20):
    X_embedded = SelectFromModel(RFC_, threshold=i).fit_transform(X,y)
    once = cross_val_score(RFC_, X_embedded, y, cv=5).mean()
    score2.append(once)
plt.figure(figsize=[20,5])
plt.plot(np.linspace(0,0.02,20),score2)
plt.xticks(np.linspace(0,0.02,20))
plt.show()
</code></pre>
<figure data-type="image" tabindex="42"><img src="https://stdasein.life/post-images/1600139155961.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>可见，当阈值约为0.0043时，模型评分最高。</p>
<p><strong>特征选择</strong></p>
<pre><code class="language-python">sfm = SelectFromModel(RFC_,threshold=0.0043)
X_em = sfm.fit(X,y)
#get_support()返回被选择的特征
features_keeped = X.columns[X_em.get_support()]
X = X[features]
X.shape
</code></pre>
<pre><code class="language-python">(254723, 18)
</code></pre>
<p>经过嵌入法的筛选，特征值只剩下最重要的18个。</p>
<p><strong>查看特征重要性排序</strong></p>
<p>识别特征重要性对业务有指导作用，重要性越高，说明特征对业务目标的影响越大，意味着在决策的时候应予以更多的考虑。</p>
<pre><code class="language-python">RFC_.fit(X,y)
importances = RFC_.feature_importances_
names = X.columns

#返回按importances的值从大到小的排序，[::-1]表示倒序
indices = np.argsort(importances)[::-1]
#可视化
fig = plt.figure()
plt.title('Feature importances')
plt.bar(range(X.shape[1]), importances[indices])
plt.xticks(range(X.shape[1]), names[indices],rotation='vertical',fontsize=14)
plt.xlim([-1, X.shape[1]])
plt.show()
</code></pre>
<figure data-type="image" tabindex="43"><img src="https://stdasein.life/post-images/1600139217762.png" alt="" width="500" height="300" loading="lazy"></figure>
<p>按重要性排序前5的特征分别是：</p>
<ul>
<li>
<p>last_fico_range_low</p>
</li>
<li>
<p>last_fico_avg</p>
</li>
<li>
<p>last_fico_range_high</p>
</li>
<li>
<p>last_pymnt_amnt</p>
</li>
<li>
<p>out_prncp</p>
</li>
</ul>
<p>其中，last_fico_avg是根据last_fico_range_high和last_fico_range_low计算出来的均值，说明特征衍生是有效果的，但同时也可能造成冗余（特征之间高度相关，即共线性），因此，我们可以继续使用过滤法消除这种冗余。</p>
<p><strong>（2）过滤法</strong></p>
<p>使用pearson相关性分析，找出并剔除冗余特征：</p>
<pre><code class="language-python">corr = X.corr()
colormap = plt.cm.plasma
plt.figure(figsize=(15,15))
plt.title('Pearson Correlation', y=1.05, size=15)
sns.heatmap(corr,linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)
</code></pre>
<figure data-type="image" tabindex="44"><img src="https://stdasein.life/post-images/1600139260602.png" alt="" width="600" height="600" loading="lazy"></figure>
<p>删除相关性在0.85以上的部分特征：</p>
<ul>
<li>loan_amnt：funded_amnt、funded_amnt_inv、installment</li>
<li>out_prncp：out_prncp_inv</li>
<li>total_pymnt：total_pymnt_inv、total_rec_prncp</li>
<li>last_fico_avg：last_fico_range_high、last_fico_range_low</li>
<li>tot_cur_bal：tot_hi_cred_lim</li>
</ul>
<pre><code class="language-python">drop_list = ['funded_amnt','funded_amnt_inv','installment',
             'out_prncp_inv','total_pymnt_inv',
             'total_rec_prncp','last_fico_range_high',
             'last_fico_range_low']
X = X.drop(drop_list,axis = 1)
X.shape
</code></pre>
<pre><code class="language-python">(254723, 10)
</code></pre>
<p>经过过滤，特征由18个下降为10个。</p>
<pre><code class="language-python">X.columns
</code></pre>
<pre><code class="language-python">Index(['loan_amnt', 'out_prncp', 'total_pymnt', 'total_rec_int',
       'total_rec_late_fee', 'last_pymnt_amnt', 'fico_avg', 'last_fico_avg',
       'debt_settlement_flag_N', 'debt_settlement_flag_Y'],
      dtype='object')
</code></pre>
<h3 id="八-模型训练">八、模型训练</h3>
<figure data-type="image" tabindex="45"><img src="https://stdasein.life/post-images/1600139294054.png" alt="" width="400" height="300" loading="lazy"></figure>
<h4 id="1处理样本不均衡">1.处理样本不均衡</h4>
<blockquote>
<p>周志华《机器学习》中介绍到，分类学习方法都有一个共同的基本假设，即<strong>不同类别的训练样例数目相当</strong>。如果不同类别的训练样例数目稍有差别，对学习结果的影响通常也不大，但若样本类别数目差别很大，属于极端不均衡，则会对学习过程（模型训练）造成困扰。这些学习算法的设计背后隐含的优化目标是数据集上的分类准确度，而这会导致学习算法在不平衡数据上更偏向于含更多样本的多数类。</p>
</blockquote>
<p><strong>查看不同类别的样本数目</strong></p>
<pre><code class="language-python">from collections import Counter
counter = Counter(y)
print(counter)
</code></pre>
<pre><code class="language-python">Counter({0: 220384, 1: 32107})
</code></pre>
<p>违约样本数量为32,107，大约占总样本的1/8，样本分布不均衡。</p>
<p><strong>SMOTE 和 RandomUnderSampler</strong></p>
<ul>
<li>
<p>SMOTE是一种<strong>过采样</strong>方法：通过增加少数类别样本数目来达到样本均衡的效果</p>
</li>
<li>
<p>RandomUnderSampler一种<strong>欠采样</strong>方法：通过减少多数类别样本的数目达到样本均衡</p>
</li>
</ul>
<p>两种方法一起使用可以有效处理样本不均衡的情况，从而提高预测的准确度。</p>
<pre><code class="language-python">from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

#用SMOTE提升少数类别样本数目，使之达到多数样本数目的30%
over = SMOTE(sampling_strategy=0.3)
#用RandomUnderSampler降低多数类别样本数目，使之比少数样本数目多40%
under = RandomUnderSampler(sampling_strategy=0.4)
#用pineline进行整合
steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)
# 转换
X_resample, y_resample = pipeline.fit_resample(X, y)
counter = Counter(y_resample)
print(counter)
</code></pre>
<pre><code class="language-python">Counter({0: 165287, 1: 66115})
</code></pre>
<p>经过均衡处理，现在的样本比例约为2.5：1</p>
<p><strong>评估均衡处理的效果</strong></p>
<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from numpy import mean

model = DecisionTreeClassifier(random_state = 42)
</code></pre>
<p>定义评估函数，注意，这里使用的评分指标是<strong>roc_auc</strong>，该指标适用于评估样本失衡情况下的模型表现</p>
<pre><code class="language-python">def evaluate(data_X, data_y):
    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)
    scores = cross_val_score(model,data_X,data_y,scoring='roc_auc',cv=cv,n_jobs=-1)
    print('Mean ROC AUC:%.3f'%(mean(scores)))
</code></pre>
<p>评估均衡处理前后的模型表现</p>
<pre><code class="language-python">evaluate(X,y)
</code></pre>
<pre><code class="language-python">Mean ROC AUC:0.934
</code></pre>
<pre><code class="language-python">evaluate(X_resample,y_resample)
</code></pre>
<pre><code class="language-python">Mean ROC AUC:0.957
</code></pre>
<p>模型评分挺高了0.023</p>
<h4 id="2模型评估">2.模型评估</h4>
<p><strong>引进常用的分类模型</strong></p>
<ul>
<li>简单线性模型：LogisticRegression</li>
<li>向量机：LinearSVC</li>
<li>最邻近算法：KNeighborsClassifier</li>
<li>决策树模型：DecisionTreeClassifier</li>
<li>聚合模型：RandomForestClassifier、AdaBoostClassifier、XGBClassifier</li>
</ul>
<pre><code class="language-python">from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
</code></pre>
<pre><code class="language-python">def get_models():
    models = dict()
    models['LR'] = LogisticRegression()
    models['SVC'] = LinearSVC()
    models['KNC'] = KNeighborsClassifier()
    models['DTC'] = DecisionTreeClassifier()
    models['forest'] = RandomForestClassifier()
    models['ABC'] = AdaBoostClassifier()
    models['XGB'] = XGBClassifier()
    return models

models = get_models()
</code></pre>
<p><strong>模型评分</strong></p>
<pre><code class="language-python">def evaluate_model(model):
    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)
    scores = cross_val_score(model,X_resample,y_resample,
                             scoring='roc_auc',cv=cv,n_jobs=-1)
    return scores
</code></pre>
<pre><code class="language-python">results, names = list(), list()
for name, model in models.items():
    scores = evaluate_model(model)
    results.append(scores)
    names.append(name)
    print('&gt;%s %.3f'%(name,mean(scores)))   
</code></pre>
<pre><code class="language-python">&gt;LR 0.980
&gt;SVC 0.981
&gt;KNC 0.988
&gt;DTC 0.957
&gt;forest 0.994
&gt;ABC 0.980
&gt;XGB 0.985
</code></pre>
<p>评分最高的是随机森林模型（0.994），最低的是决策树（0.957），但考虑到在特征选择阶段我们曾用随机森林模型进行筛选，样本存在偏向，所以不能简单地认为随机森林就一定会比其他模型表现好，对此，我们可以使用堆叠法综合各模型的优点。</p>
<h4 id="3堆叠法stacking">3.堆叠法（Stacking)</h4>
<blockquote>
<p>Stacking是常见的集成学习框架。一般来说，就是训练一个多层(一般是两层，本文中默认两层)的学习器结构，第一层(也叫学习层)用n个不同的分类器(或者参数不同的模型)将得到预测结果合并为新的特征集，并作为下一层分类器的输入。一个简单的示意图如下：</p>
</blockquote>
<figure data-type="image" tabindex="46"><img src="https://stdasein.life/post-images/1600139346351.jpg" alt="" loading="lazy"></figure>
<p>Stacking可以对多个单模型进行融合以提升整体性能，是在各种比赛中很常用的一种集成方法，详情参见<a href="https://blog.csdn.net/wstcjf/article/details/77989963">详解stacking过程</a></p>
<p><strong>定义Stacking模型</strong></p>
<p>Stacking模型一般为两层结构，第一层使用性能比较好的模型，例如XGB、随机森林等，第二层则一般使用简单的模型，例如Logistic,以防止过拟合。</p>
<pre><code class="language-python">from sklearn.ensemble import StackingClassifier
def get_stacking():
    level0 = list()
    level0.append(('SVC',LinearSVC()))
    level0.append(('KNC',KNeighborsClassifier()))
    level0.append(('forest',RandomForestClassifier()))
    level0.append(('ABC',AdaBoostClassifier()))
    level0.append(('XGB',XGBClassifier()))
    
    level1 = LogisticRegression()
    model = StackingClassifier(estimators = level0,final_estimator = level1, cv = 10)
    return model

model_stack = get_stacking()
</code></pre>
<p><strong>模型评估</strong></p>
<pre><code class="language-python">score = evaluate_model(model_stack)
print('&gt;stacking %.3f'%mean(score))
</code></pre>
<pre><code class="language-python">&gt;stacking 0.993
</code></pre>
<p>最后的Stacking模型评分为0.993，虽然略低于随机森林，但因为集成了多个模型的性能，所以稳定性应该要比随机森林要好。</p>

                </div>
            </article>
        </div>

        
            <div class="next-post">
                <div class="next gt-c-content-color-first">下一篇</div>
                <a href="https://stdasein.life/post/fang-jie-yu-ce/" class="post-title gt-a-link">
                    房价预测
                </a>
            </div>
        

        

        

        
            <script src='https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js'></script>

<style>
	div#vcomments{
		width:60%;
		max-width: 1000px;
		padding: 2.5%
	}
</style>


	<div id="vcomments"></div>

<script>
	new Valine({
		el: '#vcomments',
		appId: 'suhtzqRXVOn82V3a1GwIBG57-gzGzoHsz',
		appKey: '1WhE54RtvjL0wzsFGqJ101o6',
		avatar: 'monsterid',
		pageSize: 5,
		recordIp: false,
		placeholder: 'Just Go Go',
		visitor: false,
	});
</script>

        

        <div class="site-footer gt-c-content-color-first">
    <div class="slogan gt-c-content-color-first">Freiheit als Autonomie</div>
    <div class="social-container">
        
            
        
            
        
            
        
            
        
            
        
            
        
    </div>
    <div class="footer-info">
        Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
    </div>
    <div>
        Theme by <a href="https://imhanjie.com/" target="_blank">imhanjie</a>, Powered by <a
                href="https://github.com/getgridea/gridea" target="_blank">Gridea | <a href="https://stdasein.life/atom.xml" target="_blank">RSS</a></a>
    </div>
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

    </div>
</div>
</body>
</html>
